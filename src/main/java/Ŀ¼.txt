目录回到顶部↑
第一篇　搜索引擎入门
第1章　搜索引擎与信息检索基础　
1.1　搜索引擎的历史　
1.1.1　萌芽：archie、gopher　
1.1.2　起步：robot(网络机器人)的出现与spider(网络爬虫)　
1.1.3　发展：excite、galaxy、yahoo等　
1.1.4　繁荣：infoseek、altavista、google和baidu　
1.2　信息检索系统的基本知识　
1.2.1　什么是信息检索系统　
1.2.2　信息检索的过程　
1.2.3　传统查找的优点和不足　
1.2.4　使用索引提高检索速度　
1.2.5　倒排索引　
1.2.6　评价信息检索系统的标准　
1.3　lucene简介　
1.4　小结　
第二篇　lucene开发详解
第2章　lucene入门实例　
2.1　实例介绍　
2.1.1　实例说明　
. 2.1.2　开发过程　
2.2　准备工作　
2.2.1　将文档的全角标点转换成半角标点　
2.2.2　将大文档切分成多个小文档　
2.2.3　预处理源文件的统一接口　
2.3　创建eclipse工程　
2.3.1　准备工作　
2.3.2　创建工程并引入lucene的jar包　
2.3.3　运行文档预处理类　
2.3.4　创建处理文档的索引类：indexprocessor　
2.3.5　创建检索索引的搜索类　
2.4　运行效果　
2.5　小结　
第3章　lucene索引的建立　
3.1　document逻辑文件　
3.1.1　lucene的document　
3.1.2　为document添加多种field　
3.1.3　document的内部实现　
3.2　field的内部实现　
3.2.1　field包含的类　
3.2.2　field类的构造方法　
3.3　lucene的索引工具indexwriter　
3.3.1　indexwriter的初始化　
3.3.2　向索引添加文档　
3.3.3　限制每个field中的词条的数量　
3.4　lucene索引过程详解　
3.4.1　lucene索引建立过程概述　 
3.4.2　使用adddocument方法向索引添加文档　
3.4.3　documentwriter的adddocument方法　 
3.4.4　文档的倒排　
3.4.5　对postingtable进行排序　
3.4.6　将posting信息写入索引　
3.5　索引文件格式　
3.5.1　索引的segment　
3.5.2　.fnm格式　
3.5.3　.fdx与.fdt格式　
3.5.4　.tii与.tis格式　
3.5.5　deletable格式　 
3.5.6　复合索引格式.cfs　 
3.6　索引过程的优化　 
3.6.1　合并因子mergefactor　 
3.6.2　maxmergedocs　 
3.6.3　minmergedocs　 
3.7　索引的合并与索引的优化　
3.7.1　fsdirectory与ramdirectory　
3.7.2　使用indexwriter来合并索引　 
3.7.3　索引的优化　
3.8　从索引中删除文档　 3.8.1　索引的读取工具indexreader　 
3.8.2　使用文档id号来删除特定文档　
3.8.3　使用field信息来删除批量文档　
3.9　lucene的同步问题　
3.9.1　为什么要进行同步以及lucene的同步法则　
3.9.2　commit.lock与write.lock　 
3.10　lucene 2.0的新类：indexmodifier类　
3.11　小结　
第4章　lucene的搜索　
4.1　使用indexsearcher进行搜索　
4.1.1　初始化indexsearcher　
4.1.2　indexsearcher最简单的使用　
4.1.3　indexsearcher的多种search方法　
4.2　hits类详解　
4.2.1　hits类的公有接口　
4.2.2　效率分析　
4.2.3　hits内部的缓存　
4.2.4　hits类的工作原理　
4.3　对搜索结果的评分　
4.3.1　文档与词条的向量空间　
4.3.2　lucene的文档得分算法　
4.4　构建各种lucene内建的query对象　
4.4.1　tostring查看原子查询　
4.4.2　查询重写与权重　
4.4.3　termquery词条搜索　
4.4.4　booleanquery布尔搜索　
4.4.5　rangequery范围搜索　
4.4.6　prefixquery前缀搜索　
4.4.7　phrasequery短语搜索　
4.4.8　multiphrasequery多短语搜索　
4.4.9　fuzzyquery模糊搜索　
4.4.10　wildcardquery通配符搜索　
4.4.11　spanquery跨度搜索　 
4.5　第三方提供的query对象：regexquery　 
4.6　通过queryparser转换用户关键字　 4.6.1　词条的定义　
4.6.2　queryparser初始化　
4.6.3　改变queryparser默认的布尔逻辑　 
4.6.4　短语和queryparser　
4.6.5　fuzzyquery和queryparser　
4.6.6　通配符与queryparser　 
4.6.7　查找指定的field　
4.6.8　rangequery与queryparser　
4.6.9　queryparser和spanquery　
4.7　多field搜索与多索引搜索　
4.7.1　多域搜索multifieldqueryparser　 
4.7.2　multisearcher在多个索引上搜索　 
4.7.3　paralellmultisearcher：多线程搜索　 
4.7.4　searchable和rmi　 
4.8　小结　
第5章　排序、过滤和分页　
5.1　相关度排序　
5.1.1　使用score进行自然排序　
5.1.2　searcher的explain方法　
5.1.3　通过改变boost值来改变文档的得分　
5.2　使用sort来排序　
5.2.1　sort简介　
5.2.2　sortfield　
5.2.3　按文档得分进行排序　
5.2.4　按文档的内部id号来排序　
5.2.5　按一个或多个field来排序　
5.2.6　改变sortfield中的locale信息　
5.3　搜索的过滤器　
5.3.1　过滤器的基本结构　 
5.3.2　一个简单的filter：建立索引　
5.3.3　一个简单的filter：打印索引文档信息　 
5.3.4　一个简单的filter：安全级别与过滤器代码　
5.3.5　一个简单的filter：在搜索时应用过滤器　 
5.3.6　一个简单的filter：总结　
5.3.7　按范围过滤rangefilter　
5.3.8　在结果中查询queryfilter　
5.3.9　缓存结果：cachingwrapperfilter　
5.4　翻页问题　
5.4.1　依赖于session的翻页　 
5.4.2　多次查询　
5.4.3　缓存+多次查询　 
5.4.4　缓存+多次查询+数据库　
5.5　小结　
第6章　lucene的分析器　 
6.1　分析　
6.1.1　分词　 
6.1.2　lucene的分析器的结构　
6.1.3　lucene的分析器的实现　 
6.2　lucene与javacc　
6.2.1　javacc简介　 
6.2.2　javacc为lucene提供的分析器脚本　
6.2.3　lucene的标准分析器　
6.2.4　标准过滤器：standardfilter　
6.2.5　大小写转换器：lowercasefilter　 
6.2.6　忽略词过滤器：stopfilter　
6.3　分析器的进阶　
6.3.1　再看standardanalyzer中的管道过滤器结构　
6.3.2　长度过滤器：lengthfilter　
6.3.3　perfieldanalyzerwrapper　
6.3.4　其他　
6.4　对中文的分析　
6.4.1　现有的中文分词方式简介　
6.4.2　中科院的分词软件和je分词　
6.5　小结　
第三篇　lucene相关话题
第7章　对word、excel 和pdf的处理　
7.1　使用pdfbox处理pdf文档　
7.1.1　pdfbox的下载　
7.1.2　在eclipse中配置　
7.1.3　使用pdfbox解析pdf内容　
7.1.4　运行效果　
7.1.5　与lucene的集成　
7.2　使用xpdf来处理中文pdf文档　
7.2.1　xpdf的下载　
7.2.2　配置　
7.2.3　提取中文　
7.2.4　运行效果　
7.3　使用poi来处理excel和word文件格式　
7.3.1　对excel的处理类　
7.3.2　excelreader的运行效果　
7.3.3　poi中excel文件cell的类型　
7.3.4　对word的处理类　
7.4　使用jacob来处理word文档　
7.4.1　jacob的下载　
7.4.2　在eclipse中配置　 
7.5　小结　
第8章　compass：封装了lucene的框架　
8.1　compass简介　
8.1.1　compass的下载　
8.1.2　compass的代码片断　
8.2　compass的初始配置　
8.2.1　compass的配置文件　
8.2.2　将索引存放于内存中　
8.2.3　使用jdbc来存储索引　 
8.2.4　使用连接池来存储索引　
8.2.5　加载compass.cfg.xml文件　
8.3　域模型的配置　
8.3.1　实体代码　
8.3.2　实体关系　 
8.3.3　实体book的配置文件　
8.3.4　通用元数据定义文件(.cmd.xml)　
8.3.5　author和article的配置文件　
8.4　使用compass来建立索引　 
8.4.1　索引代码　
8.4.2　对象关系图和运行结果　
8.5　使用compass来搜索　
8.5.1　使用find()方法搜索　
8.5.2　compasshits类型　 
8.5.3　compasshit类型　
8.5.4　使用lucene语法来查找　
8.6　配置analyzer和optimizer　
8.7　小结　
第9章　lucene分布式和google search api　
9.1　lucene与分布式　
9.1.1　什么是gfs　
9.1.2　为lucene提供分布式的几点设想　
9.2　google的search api　
9.2.1　搭建环境　
9.2.2　构建搜索类　
9.2.3　设置查询时的参数和查询语法　
9.2.4　运行测试　
9.3　小结　
第四篇　网络爬虫heritrix
第10章　无比强大的网络爬虫heritrix　
10.1　heritrix使用入门　
10.1.1　下载和运行heritrix　
10.1.2　在eclipse里配置heritrix的开发环境　
10.1.3　创建一个新的抓取任务　
10.1.4　设置抓取时的处理链　
10.1.5　设置运行时的参数　 
10.1.6　运行抓取任务　
10.1.7　heritrix的镜像存储结构　
10.1.8　终止抓取或终止heritrix的运行　
10.2　heritrix的架构　
10.2.1　抓取任务crawlorder　
10.2.2　中央控制器crawlcontroller　
10.2.3　frontier链接制造工厂　
10.2.4　用berkeley db实现的bdbfrontier　
10.2.5　heritrix的多线程toethread和toepool　
10.2.6　处理链和processor　
10.3　扩展和定制heritrix　
10.3.1　向heritrix中添加自己的extractor　
10.3.2　定制queue-assignment-policy的两个问题　
10.3.3　定制queue-assignment-policy继承queueassignmentpolicy类　
10.3.4　扩展frontierscheduler来抓取特定的内容　
10.3.5　在prefetcher中取消robots.txt的限制　
10.4　小结　
第五篇　构建垂直搜索引擎
第11章　搜索引擎综合实例：准备篇　
11.1　实例简介以及实现途径　
11.1.1　选择网站　
11.1.2　太平洋电脑网和网易手机频道　
11.1.3　分析网站内容并准备抓取清单　
11.1.4　从下拉列表获得手机品牌首页　
11.1.5　解析手机品牌页面　
11.2　在heritrix中为pconline开发抓取所需的定制类　
11.2.1　保存所有产品的页面和图片　
11.2.2　不保存其他无关页面　
11.2.3　开始抓取　
11.3　在heritrix中为网易手机频道开发抓取所需的定制类　
11.3.1　分析网易手机频道　
11.3.2　设计抓取代码　
11.4　在eclipse中创建工程结构　
11.4.1　下载插件　
11.4.2　在eclipse中配置插件　
11.4.3　创建工程　
11.4.4　设置工程的context　
11.4.5　设定源代码存放和输出路径　
11.4.6　添加java代码　
11.4.7　添加jar包　
11.4.8　创建jsp文件　
11.4.9　工程整体结构一览　
11.5　设定配置文件及其相关类　
11.5.1　系统属性配置文件　
11.5.2　封装配置文件　
11.6　产品详细信息文件格式　
11.7　解析网页信息的基类extractor　
11.8　太平洋电脑网手机产品页面extractor　
11.9　pconline产品信息运行效果测试　
11.9.1　编写测试函数　
11.9.2　执行测试　
11.10　网易手机频道的产品信息运行效果　
11.11　构建产品信息词库　
11.12　数据库与索引结构　
11.12.1　定义product类　
11.12.2　确定数据库与索引的结构　
11.13　数据库处理和索引处理　
11.13.1　对数据库进行操作　
11.13.2　对索引进行操作　
11.14　调用数据库处理类和索引处理类　
11.15　运行　
11.16　小结　
第12章　使用正则表达式与htmlparser提取网页内容　
12.1　html的基本知识　
12.2　jdk中的正则表达式提取网页内容　
12.2.1　java.util.regex包　
12.2.2　正则表达式提取网页内容实例　
12.3　htmlparser提取网页内容　
12.3.1　htmlparser的下载　
12.3.2　htmlparser概述　
12.3.3　lexer的功能及实现　
12.3.4　htmlparser的功能及实现　
12.3.5　htmlparser实例　
12.4　小结　
第13章　搜索引擎综合实例：dwr　
13.1　dwr的下载　
13.2　dwr入门与实例演示　
13.2.1　创建工程结构　
13.2.2　在web.xml中配置dwr　
13.2.3　配置dwr.xml　
13.2.4　页面代码　
13.2.5　运行效果　
13.2.6　dwr与直接使用xmlhttprequest对象的比较　
13.2.7　在dwr中操纵自定义的对象　
13.2.8　查看dwr的输出日志　
13.3　dwr.xml的配置　
13.3.1　dwr.xml的标准结构　
13.3.2　[init]标签与dwr自带的converter和creator　
13.3.3　[allow]标签　
13.3.4　[signature]标签　
13.3.5　另一个例子　
13.4　util.js　
13.4.1　调用util.js　
13.4.2　使用useloadingmessage方法显示提示图标　
13.4.3　dwrutil.setvalue和dwrutil.getvalue　
13.4.4　dwrutil.getvalues和dwrutil.setvalues　
13.4.5　dwrutil.addoptions和dwrutil.removealloptions　
13.4.6　dwrutil.addrows和dwrutil.removeallrows　
13.4.7　dwrutil.todescriptivestring方法　
13.5　小结　
第14章　搜索引擎综合实例：web篇　
14.1　配置文件　
14.1.1　spring配置文件　
14.1.2　dwr配置文件　
14.1.3　web.xml　 
14.2　各种bean类　 
14.2.1　searchresult　
14.2.2　searchresults　
14.2.3　searchrequest　
14.3　searchservice的实现　
14.4　searchresultdao　
14.5　前台部分　
14.5.1　搜索主页面main.jsp　
14.5.2　图片的显示　
14.5.3　详细信息页面detail.jsp　
14.6　问题　
14.7　小结 